{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import Can_Algorithms as alg\n",
    "import logging as log\n",
    "import datetime\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "class ScanResult:\n",
    "    def __init__(self, model, precision, recall, f1_score, support):\n",
    "        self.model=model\n",
    "        self.precision = precision\n",
    "        self.recall = recall\n",
    "        self.f1_score = f1_score\n",
    "        self.support=support\n",
    "\n",
    "dsType=\"dos\"\n",
    "dos_dataPath=\"DoS_dataset.csv\"\n",
    "# dos_dataPath=\"Dataset/1000doS_dataset.csv\"\n",
    "fuzzy_dataPath=\"Dataset/1000fuzzy_dataset.csv\"\n",
    "datasets = ['dos']\n",
    "# Create a folder for log files if it doesn't exist\n",
    "log_folder = 'logs'\n",
    "os.makedirs(log_folder, exist_ok=True)\n",
    "\n",
    "# Configure logging to save log file in the folder\n",
    "log_file = os.path.join(log_folder, 'log_file.txt')\n",
    "\n",
    "# Configure logging\n",
    "log.basicConfig(filename=log_file,\n",
    "                level=log.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "#Function to convert hex string to integer\n",
    "def hex_to_int(x):\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            return int(x, 16)\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "def getDate():\n",
    "    current_ts = datetime.datetime.now()\n",
    "    formatted_time= current_ts.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    return current_ts,formatted_time\n",
    "\n",
    "def PreprocessData(data, testSize=0.2):        \n",
    "        # Assign column names\n",
    "        data.columns = ['Timestamp', 'CAN_ID', 'DLC', 'DATA0', 'DATA1',\n",
    "                        'DATA2', 'DATA3', 'DATA4', 'DATA5', 'DATA6', 'DATA7', 'Flag']\n",
    "\n",
    "        # Convert Flag column to numerical labels using label encoding\n",
    "        label_encoder = LabelEncoder()\n",
    "        data['Flag'] = label_encoder.fit_transform(data['Flag'])\n",
    "\n",
    "        data[\"Timestamp\"] = pd.to_datetime(data[\"Timestamp\"])\n",
    "\n",
    "        # Convert CAN ID and DLC to integer\n",
    "        data[\"CAN_ID\"] = data[\"CAN_ID\"].apply(lambda x: int(x, 16) if isinstance(x, str) else x)\n",
    "        data[\"DLC\"] = data[\"DLC\"].astype(int)\n",
    "       \n",
    "        # Convert DATA fields from hexadecimal strings to integers\n",
    "        for i in range(8):\n",
    "            data[f\"DATA{i}\"] = data[f\"DATA{i}\"].apply(hex_to_int).astype(float)\n",
    "\n",
    "        # Assuming 'Flag' column represents the target variable\n",
    "        X = data.drop('Flag', axis=1)  # Features\n",
    "        y = data['Flag']  # Target variable\n",
    "\n",
    "        # Splitting the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testSize, random_state=42)\n",
    "\n",
    "        # Drop 'Timestamp' column from input features\n",
    "        X_train = X_train.drop('Timestamp', axis=1)\n",
    "        X_test = X_test.drop('Timestamp', axis=1)\n",
    "\n",
    "        # Impute missing values using SimpleImputer\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "        X_train_imputed = imputer.fit_transform(X_train)\n",
    "        X_test_imputed = imputer.transform(X_test)\n",
    "        return X_train_imputed,X_test_imputed,y_train,y_test\n",
    "\n",
    "def PlotBarGraph(models,metrics,values,title,x_label,y_label):\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(5,3))\n",
    "\n",
    "    # Plot bars for each metric and model\n",
    "    bar_width = 0.2\n",
    "    index = np.arange(len(models))\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        plt.bar(index + i * bar_width, values[i], bar_width, label=metric)\n",
    "\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.xticks(index + bar_width * 1.5, models)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def PlotLineGraph(models,metrics,values,title,x_label,y_label):\n",
    "    # Plot curved lines for each metric and model\n",
    "    for i, metric in enumerate(metrics):\n",
    "        f = interp1d(np.arange(len(models)), values[i], kind='cubic')\n",
    "        x_new = np.linspace(0, len(models) - 1, 100)\n",
    "        y_new = f(x_new)\n",
    "        plt.plot(x_new, y_new, label=metric)\n",
    "\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.xticks(np.arange(len(models)), models)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath=\"\"\n",
    "for ds_name in datasets:\n",
    "    log.info(\"#####################################\")\n",
    "    log.info(\"Running dataset: [%s]\",ds_name)\n",
    "    log.info(\"#####################################\")\n",
    "\n",
    "    dataPath=dos_dataPath\n",
    "    if ds_name=='fuzzy':\n",
    "        dataPath=fuzzy_dataPath\n",
    "\n",
    "    #Load Data\n",
    "    ds = pd.read_csv(dataPath, header=None)\n",
    "\n",
    "    X_train_imputed,X_test_imputed,y_train,y_test=PreprocessData(ds,0.2)\n",
    "\n",
    "    # Define the models and their corresponding metrics\n",
    "    models = ['SVC', 'MLP', 'SGD', 'LRG']\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1_score = []\n",
    "    support = []\n",
    "    results =[]\n",
    "    \n",
    "    metrics=[]\n",
    "    values=[]\n",
    "    # Calculate total number of samples in the test set\n",
    "    total_samples = len(y_test)\n",
    "\n",
    "    # Run and evaluate each model\n",
    "    for model_name in models:\n",
    "        if model_name == 'SVC':\n",
    "            start_ts,formatted_start_ts = getDate()\n",
    "            log.info(\"Starting SVC model...[%s]\",formatted_start_ts)\n",
    "            y_pred = alg.SVC_Scan(X_train_imputed, y_train, X_test_imputed)\n",
    "            end_ts,formatted_end_ts = getDate()\n",
    "            log.info('SVC model finished. Elapsed time: %s',\n",
    "             end_ts - start_ts)\n",
    "        elif model_name == 'MLP':\n",
    "            start_ts,formatted_start_ts = getDate()\n",
    "            log.info(\"Starting MLP model...[%s]\",formatted_start_ts)\n",
    "            end_ts,formatted_end_ts = getDate()\n",
    "            log.info('MLP model finished. Elapsed time: %s',\n",
    "             end_ts - start_ts)\n",
    "            y_pred = alg.MLP_Scan(X_train_imputed, y_train, X_test_imputed)\n",
    "        elif model_name == 'SGD':\n",
    "            start_ts,formatted_start_ts = getDate()\n",
    "            log.info(\"Starting SGD model...[%s]\",formatted_start_ts)\n",
    "            y_pred = alg.SGD_Scan(X_train_imputed, y_train, X_test_imputed)\n",
    "            end_ts,formatted_end_ts = getDate()\n",
    "            log.info('SGD model finished. Elapsed time: %s',\n",
    "             end_ts - start_ts)\n",
    "        elif model_name == 'LRG':\n",
    "            start_ts,formatted_start_ts = getDate()\n",
    "            log.info(\"Starting Linear regression model...[%s]\",formatted_start_ts)\n",
    "            y_pred = alg.Linear_regression_Scan(X_train_imputed, y_train, X_test_imputed)            \n",
    "            end_ts,formatted_end_ts = getDate()\n",
    "            log.info('Linear regression model finished. Elapsed time: %s',\n",
    "             end_ts - start_ts)\n",
    "        elif model_name == 'CNN':\n",
    "            start_ts,str_ts = getDate()\n",
    "            log.info(\"Starting CNN model...[%s]\",formatted_start_ts)\n",
    "            y_pred = alg.CNN_Scan(X_train_imputed, y_train, X_test_imputed)                      \n",
    "            end_ts,end_ts = getDate()\n",
    "            log.info('CNN model finished. Elapsed time: %s',\n",
    "             end_ts - start_ts)\n",
    "\n",
    "\n",
    "        precision_score, recall_score, f1_score_val, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted', zero_division=1)\n",
    "        precision.append(precision_score * 100)\n",
    "        recall.append(recall_score * 100)\n",
    "        f1_score.append(f1_score_val * 100)\n",
    "\n",
    "        support_score=(pd.Series(y_pred).value_counts() / len(y_pred) * 100).loc[0]\n",
    "        support.append(support_score)  # Support calculated based on correct predictions\n",
    "\n",
    "    # Define the metrics to plot\n",
    "    metrics = ['Precision', 'Recall', 'F1 Score', 'Support']\n",
    "    values = [precision, recall, f1_score, support]\n",
    "\n",
    "    print(values)\n",
    "    PlotBarGraph(models,metrics,values,'Metrics by Model - '+ds_name,'Models','Score')\n",
    "    PlotLineGraph(models,metrics,values,'Metrics by Model - '+ds_name,'Models','Score')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
