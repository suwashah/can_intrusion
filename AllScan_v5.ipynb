{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import Can_Algorithms as alg\n",
    "import numpy as nmp\n",
    "import logging as log\n",
    "import datetime\n",
    "import os\n",
    "import umap\n",
    "import seaborn as sns  # for visualizing the confusion matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.manifold import TSNE\n",
    "from appconfig import Config\n",
    "from sklearn.feature_selection import RFE\n",
    "import itertools\n",
    "from tabulate import tabulate\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Config with the environment ('dev' or 'prod') and get Configuration value\n",
    "appconfig = Config('prod')\n",
    "log_folder=appconfig.getconfig_from_key(\"log_folder\")\n",
    "log_filename=appconfig.getconfig_from_key(\"log_filename\")\n",
    "datasets=appconfig.getconfig_from_key(\"datasets\")\n",
    "train_models=appconfig.getconfig_from_key(\"train_models\")\n",
    "\n",
    "# Configure logging to save log file in the folder\n",
    "os.makedirs(log_folder, exist_ok=True)\n",
    "log_file = os.path.join(log_folder, log_filename)\n",
    "log.basicConfig(filename=log_file,\n",
    "                level=log.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "                label_encoder = LabelEncoder()\n",
    "                df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "#Function to convert hex string to integer\n",
    "def hex_to_int(x):\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            return int(x, 16)\n",
    "        except ValueError:\n",
    "            return nmp.nan\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def getDate():\n",
    "    current_ts = datetime.datetime.now()\n",
    "    formatted_time= current_ts.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    return current_ts,formatted_time\n",
    "\n",
    "def PreprocessData(data): \n",
    "    ds = data\n",
    "    print(\"---Dataset Info---\")\n",
    "    print(ds.info())\n",
    "    print(\"---Dataset Objects---\")\n",
    "    print(ds.describe(include='object'))\n",
    "    print(\"---Dataset Shape---\")\n",
    "    print(ds.isnull().sum())\n",
    "\n",
    "    total = ds.shape[0]\n",
    "    missing_columns = [col for col in ds.columns if ds[col].isnull().sum() > 0]\n",
    "    for col in missing_columns:\n",
    "        null_count = ds[col].isnull().sum()\n",
    "        per = (null_count / total) * 100\n",
    "        print(f\"{col}: {null_count} ({round(per, 3)}%)\")\n",
    "\n",
    "    print(f\"Number of duplicate rows: {ds.duplicated().sum()}\")\n",
    "\n",
    "    # Plot the type of Attacks\n",
    "    sns.countplot(x=ds['Label'])\n",
    "\n",
    "    print('Class distribution Training set:')\n",
    "    print(ds['Label'].value_counts())\n",
    "\n",
    "    # Label encode the dataset\n",
    "    label_encode(ds)\n",
    "\n",
    "    ds.drop(['Timestamp'], axis=1, inplace=True)\n",
    "    X = ds.drop(['Label'], axis=1)\n",
    "    y = ds['Label']\n",
    "\n",
    "    rfc = RandomForestClassifier()\n",
    "    rfe = RFE(rfc, n_features_to_select=5)\n",
    "    rfe = rfe.fit(X, y)\n",
    "\n",
    "    feature_map = [(i, v) for i, v in itertools.zip_longest(rfe.get_support(), X.columns)]\n",
    "    selected_features = [v for i, v in feature_map if i == True]\n",
    "\n",
    "    print(\"-----------Selected features----------\")\n",
    "    print(selected_features)\n",
    "\n",
    "    X = X[selected_features]  # Set the best features for training\n",
    "\n",
    "    # Impute missing values using SimpleImputer\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X = imputer.fit_transform(X)\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    return X, y\n",
    "       \n",
    "\n",
    "def PlotBarGraph(models,metrics,values,title,x_label,y_label):\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(5,3))\n",
    "\n",
    "    # Plot bars for each metric and model\n",
    "    bar_width = 0.2\n",
    "    index = nmp.arange(len(models))\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        plt.bar(index + i * bar_width, values[i], bar_width, label=metric)\n",
    "\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.xticks(index + bar_width * 1.5, models)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def PlotLineGraph(models,metrics,values,title,x_label,y_label):\n",
    "    # Plot curved lines for each metric and model\n",
    "    for i, metric in enumerate(metrics):\n",
    "        f = interp1d(nmp.arange(len(models)), values[i], kind='cubic')\n",
    "        x_new = nmp.linspace(0, len(models) - 1, 100)\n",
    "        y_new = f(x_new)\n",
    "        plt.plot(x_new, y_new, label=metric)\n",
    "\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.xticks(nmp.arange(len(models)), models)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title=None, cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix with specified labels for normal and attack traffic.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        title = 'Confusion matrix'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)  # Ensure labels are in the correct order: [Normal, Attack]\n",
    "    # classes = ['Normal', 'Dos','Fuzzy','RPM','Gear']\n",
    "\n",
    "    # Print confusion matrix values\n",
    "    print('Confusion matrix, without normalization')\n",
    "    print(cm)\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=cmap, ax=ax)\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels')\n",
    "    ax.set_title(title)\n",
    "    ax.xaxis.set_ticklabels(['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4'])  # Adjust as necessary\n",
    "    ax.yaxis.set_ticklabels(['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4'])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datapath: Dataset/CleanDataset/Cleaned_All_dataset.csv\n",
      "---Dataset Info---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17558340 entries, 0 to 17558339\n",
      "Data columns (total 13 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   Timestamp  float64\n",
      " 1   CAN_ID     object \n",
      " 2   DLC        int64  \n",
      " 3   DATA0      object \n",
      " 4   DATA1      object \n",
      " 5   DATA2      object \n",
      " 6   DATA3      object \n",
      " 7   DATA4      object \n",
      " 8   DATA5      object \n",
      " 9   DATA6      object \n",
      " 10  DATA7      object \n",
      " 11  Flag       object \n",
      " 12  Label      int64  \n",
      "dtypes: float64(1), int64(2), object(10)\n",
      "memory usage: 1.7+ GB\n",
      "None\n",
      "---Dataset Objects---\n",
      "          CAN_ID     DATA0     DATA1     DATA2     DATA3     DATA4     DATA5  \\\n",
      "count   17558340  17558340  17558340  17558340  17558340  17558340  17558340   \n",
      "unique      2048       256       256       256       256       256       256   \n",
      "top         0316        00        00        00        00        00        00   \n",
      "freq     1481993   5793522   6936260   9683683   7598713   7443063   6242398   \n",
      "\n",
      "           DATA6     DATA7      Flag  \n",
      "count   17558340  17558340  17558340  \n",
      "unique       256       256         2  \n",
      "top           00        00         R  \n",
      "freq    10160866   9147393  15226823  \n",
      "---Dataset Shape---\n",
      "Timestamp    0\n",
      "CAN_ID       0\n",
      "DLC          0\n",
      "DATA0        0\n",
      "DATA1        0\n",
      "DATA2        0\n",
      "DATA3        0\n",
      "DATA4        0\n",
      "DATA5        0\n",
      "DATA6        0\n",
      "DATA7        0\n",
      "Flag         0\n",
      "Label        0\n",
      "dtype: int64\n",
      "Number of duplicate rows: 2673204\n",
      "Class distribution Training set:\n",
      "Label\n",
      "0    15226823\n",
      "3      654897\n",
      "4      597252\n",
      "1      587521\n",
      "2      491847\n",
      "Name: count, dtype: int64\n",
      "-----------Selected features----------\n",
      "['CAN_ID', 'DATA3', 'DATA5', 'DATA7', 'Flag']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "log.info(\"#####################################\")\n",
    "log.info(\"Running dataset: [All]\")\n",
    "log.info(\"#####################################\")\n",
    "precision = []\n",
    "recall = []\n",
    "f1_score = []\n",
    "support = []\n",
    "results =[]\n",
    "data=[]\n",
    "metrics=[]\n",
    "values=[]\n",
    "\n",
    "dataPath=appconfig.getconfig_from_keys([\"data_path\",\"all\"])  \n",
    "print(f\"Datapath: {dataPath}\")\n",
    "combined_df = pd.read_csv(dataPath)\n",
    "\n",
    "X, y = PreprocessData(combined_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "Model:  LOGR\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Report for LOGR--\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   3045365\n",
      "           1       1.00      1.00      1.00    117504\n",
      "           2       1.00      1.00      1.00     98370\n",
      "           3       1.00      1.00      1.00    130979\n",
      "           4       1.00      1.00      1.00    119450\n",
      "\n",
      "    accuracy                           1.00   3511668\n",
      "   macro avg       1.00      1.00      1.00   3511668\n",
      "weighted avg       1.00      1.00      1.00   3511668\n",
      "\n",
      "Loading existing LOGR model...\n",
      "LOGR Model loaded successfully.\n",
      "--Report for LOGR--\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   3045365\n",
      "           1       1.00      1.00      1.00    117504\n",
      "           2       1.00      1.00      1.00     98369\n",
      "           3       1.00      1.00      1.00    130980\n",
      "           4       1.00      1.00      1.00    119450\n",
      "\n",
      "    accuracy                           1.00   3511668\n",
      "   macro avg       1.00      1.00      1.00   3511668\n",
      "weighted avg       1.00      1.00      1.00   3511668\n",
      "\n",
      "Loading existing LOGR model...\n",
      "LOGR Model loaded successfully.\n",
      "--Report for LOGR--\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   3045365\n",
      "           1       1.00      1.00      1.00    117504\n",
      "           2       1.00      1.00      1.00     98369\n",
      "           3       1.00      1.00      1.00    130980\n",
      "           4       1.00      1.00      1.00    119450\n",
      "\n",
      "    accuracy                           1.00   3511668\n",
      "   macro avg       1.00      1.00      1.00   3511668\n",
      "weighted avg       1.00      1.00      1.00   3511668\n",
      "\n",
      "Loading existing LOGR model...\n",
      "LOGR Model loaded successfully.\n",
      "--Report for LOGR--\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   3045364\n",
      "           1       1.00      1.00      1.00    117505\n",
      "           2       1.00      1.00      1.00     98369\n",
      "           3       1.00      1.00      1.00    130979\n",
      "           4       1.00      1.00      1.00    119451\n",
      "\n",
      "    accuracy                           1.00   3511668\n",
      "   macro avg       1.00      1.00      1.00   3511668\n",
      "weighted avg       1.00      1.00      1.00   3511668\n",
      "\n",
      "Loading existing LOGR model...\n",
      "LOGR Model loaded successfully.\n",
      "--Report for LOGR--\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   3045364\n",
      "           1       1.00      1.00      1.00    117504\n",
      "           2       1.00      1.00      1.00     98370\n",
      "           3       1.00      1.00      1.00    130979\n",
      "           4       1.00      1.00      1.00    119451\n",
      "\n",
      "    accuracy                           1.00   3511668\n",
      "   macro avg       1.00      1.00      1.00   3511668\n",
      "weighted avg       1.00      1.00      1.00   3511668\n",
      "\n",
      "-------------------------------\n",
      "Model:  MLP\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 45.4 GiB for an array with shape (60907290, 100) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m start_ts, formatted_start_ts \u001b[38;5;241m=\u001b[39m getDate()\n\u001b[0;32m     36\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting MLP model...[\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m, formatted_start_ts)\n\u001b[1;32m---> 37\u001b[0m y_pred, training_score, testing_score \u001b[38;5;241m=\u001b[39m alg\u001b[38;5;241m.\u001b[39mMLP_Scan(x_train, y_train, x_test, y_test)\n\u001b[0;32m     38\u001b[0m end_ts, formatted_end_ts \u001b[38;5;241m=\u001b[39m getDate()\n\u001b[0;32m     39\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLP model finished. Elapsed time: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m, end_ts \u001b[38;5;241m-\u001b[39m start_ts)\n",
      "File \u001b[1;32mc:\\Subash\\Important\\CDU\\MIT Cyber Security\\2024 Third Semester\\PRT840 IT Thesis\\CanIntrusionproject\\can_intrusion\\Can_Algorithms.py:78\u001b[0m, in \u001b[0;36mMLP_Scan\u001b[1;34m(x_train, y_train, x_test, y_test)\u001b[0m\n\u001b[0;32m     75\u001b[0m     mlp_classifier\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n\u001b[0;32m     76\u001b[0m     dump(mlp_classifier, model_filename)\n\u001b[1;32m---> 78\u001b[0m train_score, test_score \u001b[38;5;241m=\u001b[39m mlp_classifier\u001b[38;5;241m.\u001b[39mscore(\n\u001b[0;32m     79\u001b[0m     x_train, y_train), mlp_classifier\u001b[38;5;241m.\u001b[39mscore(x_test, y_test)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m     81\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m mlp_classifier\u001b[38;5;241m.\u001b[39mpredict(x_test)\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py:668\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    644\u001b[0m \u001b[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[0;32m    645\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;124;03m    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\u001b[39;00m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m--> 668\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(X), sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1156\u001b[0m, in \u001b[0;36mMLPClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict using the multi-layer perceptron classifier.\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \n\u001b[0;32m   1145\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1153\u001b[0m \u001b[38;5;124;03m    The predicted classes.\u001b[39;00m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(X)\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1160\u001b[0m, in \u001b[0;36mMLPClassifier._predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1159\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Private predict method with optional input validation\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1160\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pass_fast(X, check_input\u001b[38;5;241m=\u001b[39mcheck_input)\n\u001b[0;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1163\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:210\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._forward_pass_fast\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    208\u001b[0m hidden_activation \u001b[38;5;241m=\u001b[39m ACTIVATIONS[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation]\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layers_ \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 210\u001b[0m     activation \u001b[38;5;241m=\u001b[39m safe_sparse_dot(activation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoefs_[i])\n\u001b[0;32m    211\u001b[0m     activation \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercepts_[i]\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layers_ \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Anaconda\\Lib\\site-packages\\sklearn\\utils\\extmath.py:189\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    187\u001b[0m         ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a, b)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 189\u001b[0m     ret \u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m@\u001b[39m b\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    192\u001b[0m     sparse\u001b[38;5;241m.\u001b[39missparse(a)\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    196\u001b[0m ):\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 45.4 GiB for an array with shape (60907290, 100) and data type float64"
     ]
    }
   ],
   "source": [
    "\n",
    "# Cross-validation and SMOTE\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "for model_name in train_models:\n",
    "    print('-------------------------------')\n",
    "    print('Model: ', model_name)\n",
    "    print('-------------------------------')\n",
    "    \n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    support_scores = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        x_train, x_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Apply SMOTE\n",
    "        x_train, y_train = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "        if model_name == 'SVC':\n",
    "            start_ts, formatted_start_ts = getDate()\n",
    "            log.info(\"Starting SVC model...[%s]\", formatted_start_ts)\n",
    "            y_pred, training_score, testing_score = alg.SVC_Scan(x_train, y_train, x_test, y_test)\n",
    "            end_ts, formatted_end_ts = getDate()\n",
    "            log.info('SVC model finished. Elapsed time: %s', end_ts - start_ts)\n",
    "        elif model_name == 'LOGR':\n",
    "            start_ts, formatted_start_ts = getDate()\n",
    "            log.info(\"Starting Logistic Regression model...[%s]\", formatted_start_ts)\n",
    "            y_pred, training_score, testing_score = alg.Logistic_regression_Scan(x_train, y_train, x_test, y_test)\n",
    "            end_ts, formatted_end_ts = getDate()\n",
    "            log.info('Logistic Regression model finished. Elapsed time: %s', end_ts - start_ts)\n",
    "        elif model_name == 'MLP':\n",
    "            start_ts, formatted_start_ts = getDate()\n",
    "            log.info(\"Starting MLP model...[%s]\", formatted_start_ts)\n",
    "            y_pred, training_score, testing_score = alg.MLP_Scan(x_train, y_train, x_test, y_test)\n",
    "            end_ts, formatted_end_ts = getDate()\n",
    "            log.info('MLP model finished. Elapsed time: %s', end_ts - start_ts)\n",
    "        elif model_name == 'SGD':\n",
    "            start_ts, formatted_start_ts = getDate()\n",
    "            log.info(\"Starting SGD model...[%s]\", formatted_start_ts)\n",
    "            y_pred, training_score, testing_score = alg.SGD_Scan(x_train, y_train, x_test, y_test)\n",
    "            end_ts, formatted_end_ts = getDate()\n",
    "            log.info('SGD model finished. Elapsed time: %s', end_ts - start_ts)\n",
    "        elif model_name == 'LRG':\n",
    "            start_ts, formatted_start_ts = getDate()\n",
    "            log.info(\"Starting Linear Regression model...[%s]\", formatted_start_ts)\n",
    "            y_pred, training_score, testing_score = alg.Linear_regression_Scan(x_train, y_train, x_test, y_test)\n",
    "            end_ts, formatted_end_ts = getDate()\n",
    "            log.info('Linear Regression model finished. Elapsed time: %s', end_ts - start_ts)\n",
    "        elif model_name == 'CNN':\n",
    "            start_ts, formatted_start_ts = getDate()\n",
    "            log.info(\"Starting CNN model...[%s]\", formatted_start_ts)\n",
    "            y_pred, training_score, testing_score = alg.CNN_Scan(x_train, y_train, x_test, y_test)\n",
    "            end_ts, formatted_end_ts = getDate()\n",
    "            log.info('CNN model finished. Elapsed time: %s', end_ts - start_ts)\n",
    "        \n",
    "        print(f\"--Report for \"+model_name+\"--\")\n",
    "        print(classification_report(y_test, y_pred, zero_division=1))\n",
    "        precision_score, recall_score, f1_score_val, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted', zero_division=1)\n",
    "        support_score = (pd.Series(y_pred).value_counts() / len(y_pred)).loc[0]\n",
    "        \n",
    "        precision_scores.append(precision_score)\n",
    "        recall_scores.append(recall_score)\n",
    "        f1_scores.append(f1_score_val)\n",
    "        support_scores.append(support_score)\n",
    "\n",
    "    precision.append(nmp.mean(precision_scores))\n",
    "    recall.append(nmp.mean(recall_scores))\n",
    "    f1_score.append(nmp.mean(f1_scores))\n",
    "    support.append(nmp.mean(support_scores))\n",
    "\n",
    "    data.append([model_name, nmp.mean(training_score), nmp.mean(testing_score)])\n",
    "\n",
    "col_names = [\"Model\", \"Train Score\", \"Test Score\"]\n",
    "print(tabulate(data, headers=col_names, tablefmt=\"fancy_grid\"))\n",
    "\n",
    "metrics = ['Precision', 'Recall', 'F1 Score', 'Support']\n",
    "values = [precision, recall, f1_score, support]\n",
    "PlotBarGraph(train_models, metrics, values, 'Metrics by dataset - All dataset', 'Models', 'Score')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
